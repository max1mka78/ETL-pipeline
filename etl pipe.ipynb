{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d060b603-9a6b-43b4-a3db-303f19697d47",
   "metadata": {},
   "source": [
    "# ETL-процесс в Airflow: задача\n",
    "\n",
    "## Цель\n",
    "\n",
    "Реализовать DAG в **Apache Airflow**, который ежедневно считает метрики за **вчерашнюю дату** и загружает их в **ClickHouse** в финальную таблицу в схеме `test`.\n",
    "\n",
    "---\n",
    "\n",
    "## Основные шаги DAG\n",
    "\n",
    "### 1. **Параллельная обработка двух таблиц**\n",
    "\n",
    "- **feed_actions**  \n",
    "  Для каждого пользователя:\n",
    "  - Количество просмотров (`views`)\n",
    "  - Количество лайков (`likes`)\n",
    "\n",
    "- **message_actions**  \n",
    "  Для каждого пользователя:\n",
    "  - Количество **отправленных** сообщений (`messages_sent`)\n",
    "  - Количество **полученных** сообщений (`messages_received`)\n",
    "  - Число **уникальных пользователей, которым он писал** (`users_sent`)\n",
    "  - Число **уникальных пользователей, которые писали ему** (`users_received`)\n",
    "\n",
    "> Каждая из этих выгрузок реализуется в **отдельном таске**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Объединение таблиц**\n",
    "\n",
    "После обработки обеих таблиц — объединяем их в одну по `user_id`.  \n",
    "Получаем единую таблицу с метриками по пользователям.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Агрегация по срезам**\n",
    "\n",
    "Для объединённой таблицы считаем метрики в трёх срезах:\n",
    "\n",
    "| Срез | Описание |\n",
    "|------|----------|\n",
    "| **gender** | по полу |\n",
    "| **age** | по возрастным группам |\n",
    "| **os** | по типу операционной системы |\n",
    "\n",
    "Каждый срез — **отдельный таск**.\n",
    "\n",
    "Метрики:\n",
    "- `views`\n",
    "- `likes`\n",
    "- `messages_received`\n",
    "- `messages_sent`\n",
    "- `users_received`\n",
    "- `users_sent`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Загрузка в ClickHouse**\n",
    "\n",
    "Финальная таблица должна содержать следующие поля:\n",
    "\n",
    "| Поле | Описание |\n",
    "|------|----------|\n",
    "| `event_date` | Дата (вчерашний день) |\n",
    "| `dimension` | Название среза: `gender`, `age`, `os` |\n",
    "| `dimension_value` | Значение среза (например, `iOS`, `male`, `25-34`) |\n",
    "| `views` | Число просмотров |\n",
    "| `likes` | Число лайков |\n",
    "| `messages_received` | Число полученных сообщений |\n",
    "| `messages_sent` | Число отправленных сообщений |\n",
    "| `users_received` | Скольким пользователям написал пользователь |\n",
    "| `users_sent` | Сколько пользователей написали пользователю |\n",
    "\n",
    "> Каждый день таблица должна **дополняться новыми данными** за предыдущий день.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2001f-5c31-4d21-891d-126f1e6f906c",
   "metadata": {},
   "source": [
    "Я представлю реализацию кода здесь в формате py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76dc419-9df8-42d4-8d29-2ff3e67018dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandahouse as ph\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context\n",
    "\n",
    "connection = {\n",
    "    'host': 'https://clickhouse.lab.karpov.courses',\n",
    "    'password': 'dpo_python_2020',\n",
    "    'user': 'student',\n",
    "    'database': 'simulator_20250520'\n",
    "}\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'm.kruzhalin',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2025, 6, 19)\n",
    "}\n",
    "\n",
    "#интервал выполнения дагов\n",
    "schedule_interval = '0 23 * * *'\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def maximkruzhalin_dag_etl():\n",
    "    \n",
    "    @task()\n",
    "    def extract_one():\n",
    "        q = \"\"\"\n",
    "            SELECT \n",
    "                user_id,\n",
    "                yesterday() AS event_date,\n",
    "                sum(action = 'like') as likes,\n",
    "                sum(action = 'view') as views,\n",
    "                gender, age, os\n",
    "            FROM simulator_20250520.feed_actions\n",
    "            WHERE time >= yesterday() AND time < today()\n",
    "            GROUP BY user_id, gender, age, os\n",
    "            \"\"\"\n",
    "\n",
    "# Получаем данные\n",
    "        df_feed = ph.read_clickhouse(q, connection=connection)\n",
    "        return df_feed\n",
    "    \n",
    "    @task()\n",
    "    def extract_two():\n",
    "        qq = \"\"\"\n",
    "            SELECT \n",
    "                u.user_id,\n",
    "                COALESCE(sum(sent.sent_count), 0) AS messages_sent,\n",
    "                COALESCE(sum(received.received_count), 0) AS messages_received,\n",
    "                COALESCE(sum(sent.unique_receivers), 0) AS  users_sent,\n",
    "                COALESCE(sum(received.unique_senders), 0) AS users_received,\n",
    "                any(u_info.gender) AS gender,\n",
    "                any(u_info.age) AS age,\n",
    "                any(u_info.os) AS os,\n",
    "                yesterday() AS event_date\n",
    "            FROM (\n",
    "                -- Берем только user_id, для которых есть информация в message_actions\n",
    "                SELECT DISTINCT user_id \n",
    "                FROM simulator_20250520.message_actions\n",
    "                WHERE time >= yesterday() AND time < today()\n",
    "                UNION DISTINCT\n",
    "                SELECT DISTINCT receiver_id \n",
    "                FROM simulator_20250520.message_actions\n",
    "                WHERE time >= yesterday() AND time < today()\n",
    "                AND receiver_id IN (SELECT user_id FROM simulator_20250520.message_actions WHERE time >= yesterday() AND time < today())\n",
    "            ) AS u\n",
    "            -- Получаем информацию о пользователе\n",
    "            JOIN (\n",
    "                SELECT \n",
    "                    user_id,\n",
    "                    argMax(gender, time) AS gender,\n",
    "                    argMax(age, time) AS age,\n",
    "                    argMax(os, time) AS os\n",
    "                FROM simulator_20250520.message_actions\n",
    "                WHERE time >= yesterday() AND time < today()\n",
    "                GROUP BY user_id\n",
    "            ) AS u_info ON u.user_id = u_info.user_id\n",
    "            -- Отправленные сообщения за вчера\n",
    "            LEFT JOIN (\n",
    "                SELECT \n",
    "                    user_id,\n",
    "                    COUNT(*) AS sent_count,\n",
    "                    COUNT(DISTINCT receiver_id) AS unique_receivers\n",
    "                FROM simulator_20250520.message_actions\n",
    "                WHERE time >= yesterday() AND time < today()\n",
    "                GROUP BY user_id\n",
    "            ) AS sent ON u.user_id = sent.user_id\n",
    "            -- Полученные сообщения за вчера\n",
    "            LEFT JOIN (\n",
    "                SELECT \n",
    "                    receiver_id,\n",
    "                    COUNT(*) AS received_count,\n",
    "                    COUNT(DISTINCT user_id) AS unique_senders\n",
    "                FROM simulator_20250520.message_actions\n",
    "                WHERE time >= yesterday() AND time < today()\n",
    "                GROUP BY receiver_id\n",
    "            ) AS received ON u.user_id = received.receiver_id\n",
    "            GROUP BY u.user_id;\n",
    "            \"\"\"\n",
    "\n",
    "# Получаем данные\n",
    "        df_message = ph.read_clickhouse(qq, connection=connection)\n",
    "        return df_message\n",
    "    \n",
    "    @task\n",
    "    def transfrom_merge_tables(df_feed, df_message):\n",
    "        merged_df = pd.merge(\n",
    "            df_feed,\n",
    "            df_message.rename(columns={'u.user_id': 'user_id'}),  # Переименовываем перед объединением\n",
    "            on='user_id',\n",
    "            how='outer',\n",
    "            suffixes=('_feed', '_message')\n",
    ")\n",
    "        duplicate_columns = ['user_id', 'event_date', 'age', 'os', 'gender']\n",
    "\n",
    "        for col in duplicate_columns:\n",
    "    # Формируем имена колонок с суффиксами\n",
    "            col_feed = f'{col}_feed' if f'{col}_feed' in merged_df.columns else col\n",
    "            col_message = f'{col}_message' if f'{col}_message' in merged_df.columns else col\n",
    "    \n",
    "    # Если колонка есть в обеих таблицах\n",
    "            if col_feed in merged_df.columns and col_message in merged_df.columns:\n",
    "        # Создаём единую колонку (берём _feed, если не 0/NaN, иначе _message)\n",
    "                merged_df[col] = merged_df[col_feed].where(\n",
    "                    (merged_df[col_feed] != 0) & (merged_df[col_feed].notna()),\n",
    "                    merged_df[col_message]\n",
    "        )\n",
    "        # Удаляем исходные колонки\n",
    "                merged_df = merged_df.drop(columns=[col_feed, col_message])\n",
    "            \n",
    "        merged_df = merged_df.fillna(0)\n",
    "            \n",
    "        numeric_cols = [\n",
    "            'views', \n",
    "            'likes',\n",
    "            'messages_sent',      \n",
    "            'messages_received',  \n",
    "            'users_sent',         \n",
    "            'users_received',     \n",
    "            'age', 'gender'\n",
    "        ]\n",
    "\n",
    "# Приводим к целочисленному типу\n",
    "        merged_df[numeric_cols] = merged_df[numeric_cols].astype(int)\n",
    "        return merged_df\n",
    "    \n",
    "    @task\n",
    "    def gender(merged_df):\n",
    "        gender_stats = merged_df.groupby(['event_date', 'gender']).agg({\n",
    "    'views': 'sum',\n",
    "    'likes': 'sum',\n",
    "    'messages_sent': 'sum',          \n",
    "    'messages_received': 'sum',      \n",
    "    'users_sent': 'sum',             \n",
    "    'users_received': 'sum'          \n",
    "}).reset_index()\n",
    "\n",
    "# Добавляем название среза (dimension)\n",
    "        gender_stats['dimension'] = 'gender'\n",
    "        gender_stats = gender_stats.rename(columns={'gender': 'dimension_value'})\n",
    "        return gender_stats\n",
    "    \n",
    "    @task\n",
    "    def os(merged_df):\n",
    "        os_stats = merged_df.groupby(['event_date', 'os']).agg({\n",
    "    'views': 'sum',\n",
    "    'likes': 'sum',\n",
    "    'messages_sent': 'sum',\n",
    "    'messages_received': 'sum',\n",
    "    'users_sent': 'sum',             \n",
    "    'users_received': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Добавляем название среза\n",
    "        os_stats['dimension'] = 'os'\n",
    "        os_stats = os_stats.rename(columns={'os': 'dimension_value'})\n",
    "        return os_stats\n",
    "    \n",
    "    @task\n",
    "    def age(merged_df):\n",
    "        age_stats = merged_df.groupby(['event_date', 'age']).agg({\n",
    "            'views': 'sum',\n",
    "            'likes': 'sum',\n",
    "            'messages_sent': 'sum',\n",
    "            'messages_received': 'sum',\n",
    "            'users_sent': 'sum',\n",
    "            'users_received': 'sum'\n",
    "        }).reset_index()\n",
    "\n",
    "        # Добавляем название среза\n",
    "        age_stats['dimension'] = 'age'\n",
    "        age_stats = age_stats.rename(columns={'age': 'dimension_value'})\n",
    "        return age_stats\n",
    "    \n",
    "    @task\n",
    "    def final_table(gender_stats, os_stats, age_stats):\n",
    "        final_stats = pd.concat([gender_stats, age_stats, os_stats], ignore_index=True)\n",
    "    \n",
    "    # Задаем нужный порядок столбцов\n",
    "        correct_order = [\n",
    "            'event_date',\n",
    "            'dimension',\n",
    "            'dimension_value',\n",
    "            'views',\n",
    "            'likes',\n",
    "            'messages_received',\n",
    "            'messages_sent',\n",
    "            'users_received',\n",
    "            'users_sent'\n",
    "        ]\n",
    "    \n",
    "        # Переупорядочиваем DataFrame\n",
    "        final_stats = final_stats[correct_order]\n",
    "\n",
    "        final_stats = final_stats.astype({\n",
    "            'event_date': 'datetime64[ns]',\n",
    "            'dimension': 'str',\n",
    "            'dimension_value': 'str',\n",
    "            'views': 'int64',\n",
    "            'likes': 'int64',\n",
    "            'messages_received': 'int64',\n",
    "            'messages_sent': 'int64',\n",
    "            'users_received': 'int64',\n",
    "            'users_sent': 'int64'\n",
    "        })\n",
    "\n",
    "        return final_stats\n",
    "    \n",
    "    @task\n",
    "    def load_to_clickhouse(final_stats, table_name):\n",
    "        clickhouse_test_connection = {\n",
    "            'host': 'https://clickhouse.lab.karpov.courses',\n",
    "            'database': 'test',\n",
    "            'user': 'student-rw',\n",
    "            'password': '656e2b0c9c'\n",
    "        }\n",
    "\n",
    "        # Дополнительная обработка данных перед загрузкой\n",
    "        final_stats = final_stats.copy()\n",
    "\n",
    "        # 1. Преобразуем дату в правильный формат (без кавычек)\n",
    "        final_stats['event_date'] = pd.to_datetime(final_stats['event_date']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # 2. Убедимся, что строковые значения не содержат лишних кавычек\n",
    "        string_cols = ['dimension', 'dimension_value']\n",
    "        for col in string_cols:\n",
    "            final_stats[col] = final_stats[col].astype(str).str.replace('\"', '')\n",
    "\n",
    "        # 3. Заменим возможные NaN в числовых колонках\n",
    "        numeric_cols = ['views', 'likes', 'messages_received', 'messages_sent', 'users_received', 'users_sent']\n",
    "        final_stats[numeric_cols] = final_stats[numeric_cols].fillna(0).astype('int64')\n",
    "\n",
    "        # Создаем таблицу если не существует\n",
    "        create_table_query = '''CREATE TABLE IF NOT EXISTS test.m_kruzhalin(\n",
    "        event_date DateTime,\n",
    "        dimension String,\n",
    "        dimension_value String,\n",
    "        views UInt64,\n",
    "        likes UInt64,\n",
    "        messages_received UInt64,\n",
    "        messages_sent UInt64,\n",
    "        users_received UInt64,\n",
    "        users_sent UInt64\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY (event_date, dimension, dimension_value);\n",
    "    '''\n",
    "        ph.execute(create_table_query, clickhouse_test_connection)\n",
    "        ph.to_clickhouse(df=final_stats, table=\"m_kruzhalin\", connection=clickhouse_test_connection, index=False)\n",
    "        \n",
    "    df_feed = extract_one()\n",
    "    df_message = extract_two()\n",
    "    \n",
    "    merged_df = transfrom_merge_tables(df_feed, df_message)\n",
    "    \n",
    "    gender_stats = gender(merged_df)\n",
    "    os_stats = os(merged_df)\n",
    "    age_stats = age(merged_df)\n",
    "    \n",
    "    final_stats = final_table(gender_stats, os_stats, age_stats)\n",
    "    load_to_clickhouse(final_stats, 'm_kruzhalin')\n",
    "\n",
    "maximkruzhalin_dag_etl = maximkruzhalin_dag_etl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52334c-a043-4baf-bd70-be0f0db07d53",
   "metadata": {},
   "source": [
    "![Описание изображения](etl_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d31f9-196a-4285-9961-82dd8a901071",
   "metadata": {},
   "source": [
    "![Описание](etl_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52334c-a043-4baf-bd70-be0f0db07d53",
   "metadata": {},
   "source": [
    "![Опис](etl_redash.png)"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
